{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inventory Optimization for Retail - LSTM Model Development\n",
    "\n",
    "This notebook focuses on building and training an LSTM model for time series forecasting of retail inventory demand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# For data preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# For LSTM model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "sns.set_palette('Set2')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Preprocessed Data\n",
    "\n",
    "First, let's load the preprocessed data from the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load the training and testing data\n",
    "train_data = pd.read_csv('../data/train_data.csv')\n",
    "test_data = pd.read_csv('../data/test_data.csv')\n",
    "\n",
    "# Convert date columns to datetime\n",
    "train_data['Week_Start'] = pd.to_datetime(train_data['Week_Start'])\n",
    "test_data['Week_Start'] = pd.to_datetime(test_data['Week_Start'])\n",
    "\n",
    "# Display the first few rows of the training data\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare Data for LSTM\n",
    "\n",
    "LSTM models require data to be in a specific format. We need to:\n",
    "1. Scale the data\n",
    "2. Create sequences of past observations\n",
    "3. Reshape the data for LSTM input (samples, time steps, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Function to prepare data for a specific product-store combination\n",
    "def prepare_lstm_data(product_id, store_id, sequence_length=4):\n",
    "    # Filter data for the specific product and store\n",
    "    train_product_store = train_data[(train_data['Product_ID'] == product_id) & \n",
    "                                    (train_data['Store_ID'] == store_id)].sort_values('Week_Start')\n",
    "    test_product_store = test_data[(test_data['Product_ID'] == product_id) & \n",
    "                                   (test_data['Store_ID'] == store_id)].sort_values('Week_Start')\n",
    "    \n",
    "    # Select features\n",
    "    features = ['Sales_Quantity', 'Inventory_Level', 'Sales_Lag_1', 'Sales_Lag_2', 'Sales_Lag_3', 'Sales_Lag_4',\n",
    "                'Sales_Rolling_2', 'Sales_Rolling_4', 'Sales_Rolling_8']\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    train_scaled = scaler.fit_transform(train_product_store[features])\n",
    "    test_scaled = scaler.transform(test_product_store[features])\n",
    "    \n",
    "    # Create sequences\n",
    "    X_train, y_train = create_sequences(train_scaled, sequence_length)\n",
    "    X_test, y_test = create_sequences(test_scaled, sequence_length)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test, scaler, train_product_store, test_product_store\n",
    "\n",
    "# Function to create sequences\n",
    "def create_sequences(data, sequence_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        X.append(data[i:i+sequence_length])\n",
    "        y.append(data[i+sequence_length, 0])  # Target is Sales_Quantity\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build LSTM Model\n",
    "\n",
    "Now, let's build an LSTM model for time series forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Function to build LSTM model\n",
    "def build_lstm_model(input_shape):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # First LSTM layer with return sequences\n",
    "    model.add(LSTM(50, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # Second LSTM layer\n",
    "    model.add(LSTM(50))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # Dense output layer\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train and Evaluate Model\n",
    "\n",
    "Let's train the model for a specific product-store combination and evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Select a product-store combination for demonstration\n",
    "product_id = train_data['Product_ID'].unique()[0]\n",
    "store_id = train_data['Store_ID'].unique()[0]\n",
    "\n",
    "# Prepare data\n",
    "sequence_length = 4\n",
    "X_train, y_train, X_test, y_test, scaler, train_product_store, test_product_store = prepare_lstm_data(\n",
    "    product_id, store_id, sequence_length\n",
    ")\n",
    "\n",
    "# Build model\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "model = build_lstm_model(input_shape)\n",
    "\n",
    "# Display model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Set up callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('../models/lstm_model.h5', save_best_only=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping, model_checkpoint],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('../images/model_loss.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Make Predictions\n",
    "\n",
    "Now, let's use the trained model to make predictions on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Inverse transform the predictions and actual values\n",
    "# Create dummy arrays with the same shape as the original scaled data\n",
    "y_pred_dummy = np.zeros((len(y_pred), scaler.n_features_in_))\n",
    "y_pred_dummy[:, 0] = y_pred.flatten()  # Set the first column (Sales_Quantity) to the predicted values\n",
    "\n",
    "y_test_dummy = np.zeros((len(y_test), scaler.n_features_in_))\n",
    "y_test_dummy[:, 0] = y_test  # Set the first column (Sales_Quantity) to the actual values\n",
    "\n",
    "# Inverse transform\n",
    "y_pred_inv = scaler.inverse_transform(y_pred_dummy)[:, 0]\n",
    "y_test_inv = scaler.inverse_transform(y_test_dummy)[:, 0]\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mae = mean_absolute_error(y_test_inv, y_pred_inv)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_inv, y_pred_inv))\n",
    "mape = np.mean(np.abs((y_test_inv - y_pred_inv) / y_test_inv)) * 100\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot actual vs predicted values\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_test_inv, label='Actual Sales')\n",
    "plt.plot(y_pred_inv, label='Predicted Sales')\n",
    "plt.title(f'Actual vs Predicted Sales for {product_id} at {store_id}')\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Sales Quantity')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../images/actual_vs_predicted.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Forecast Future Demand\n",
    "\n",
    "Let's forecast the demand for the next 4 weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Function to forecast future demand\n",
    "def forecast_future_demand(model, last_sequence, scaler, n_steps=4):\n",
    "    # Make a copy of the last sequence\n",
    "    curr_sequence = last_sequence.copy()\n",
    "    future_predictions = []\n",
    "    \n",
    "    for _ in range(n_steps):\n",
    "        # Predict the next value\n",
    "        pred = model.predict(curr_sequence.reshape(1, curr_sequence.shape[0], curr_sequence.shape[1]))\n",
    "        \n",
    "        # Create a dummy row with the prediction\n",
    "        dummy_row = np.zeros((1, scaler.n_features_in_))\n",
    "        dummy_row[0, 0] = pred[0, 0]  # Set Sales_Quantity\n",
    "        \n",
    "        # Inverse transform to get the actual value\n",
    "        pred_inv = scaler.inverse_transform(dummy_row)[0, 0]\n",
    "        future_predictions.append(pred_inv)\n",
    "        \n",
    "        # Update the sequence for the next prediction\n",
    "        # Shift the sequence and add the new prediction\n",
    "        new_row = curr_sequence[-1].copy()\n",
    "        new_row[0] = pred[0, 0]  # Update Sales_Quantity\n",
    "        # Update lag values (simplified approach)\n",
    "        new_row[2] = curr_sequence[-1, 0]  # Sales_Lag_1 = previous Sales_Quantity\n",
    "        new_row[3] = curr_sequence[-1, 2]  # Sales_Lag_2 = previous Sales_Lag_1\n",
    "        new_row[4] = curr_sequence[-1, 3]  # Sales_Lag_3 = previous Sales_Lag_2\n",
    "        new_row[5] = curr_sequence[-1, 4]  # Sales_Lag_4 = previous Sales_Lag_3\n",
    "        # Update rolling averages (simplified approach)\n",
    "        new_row[6] = (curr_sequence[-1, 0] + pred[0, 0]) / 2  # Sales_Rolling_2\n",
    "        new_row[7] = (curr_sequence[-1, 0] + curr_sequence[-2, 0] + curr_sequence[-3, 0] + pred[0, 0]) / 4  # Sales_Rolling_4\n",
    "        new_row[8] = curr_sequence[-1, 8]  # Keep Sales_Rolling_8 the same (simplified)\n",
    "        \n",
    "        curr_sequence = np.vstack([curr_sequence[1:], new_row])\n",
    "    \n",
    "    return future_predictions\n",
    "\n",
    "# Get the last sequence from the test data\n",
    "last_sequence = X_test[-1]\n",
    "\n",
    "# Forecast future demand\n",
    "future_predictions = forecast_future_demand(model, last_sequence, scaler, n_steps=4)\n",
    "\n",
    "# Create dates for the future predictions\n",
    "last_date = test_product_store['Week_Start'].iloc[-1]\n",
    "future_dates = [last_date + pd.Timedelta(weeks=i+1) for i in range(len(future_predictions))]\n",
    "\n",
    "# Display the forecasted demand\n",
    "forecast_df = pd.DataFrame({\n",
    "    'Week_Start': future_dates,\n",
    "    'Forecasted_Sales': future_predictions\n",
    "})\n",
    "print(\"Forecasted Sales for the Next 4 Weeks:\")\n",
    "print(forecast_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot historical and forecasted sales\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Historical data\n",
    "historical_dates = list(train_product_store['Week_Start']) + list(test_product_store['Week_Start'])\n",
    "historical_sales = list(train_product_store['Sales_Quantity']) + list(test_product_store['Sales_Quantity'])\n",
    "plt.plot(historical_dates, historical_sales, label='Historical Sales', color='blue')\n",
    "\n",
    "# Forecasted data\n",
    "plt.plot(future_dates, future_predictions, label='Forecasted Sales', color='red', linestyle='--', marker='o')\n",
    "\n",
    "# Add vertical line to separate historical and forecasted data\n",
    "plt.axvline(x=last_date, color='gray', linestyle='--')\n",
    "plt.text(last_date, max(historical_sales), 'Forecast Start', ha='right', va='top')\n",
    "\n",
    "plt.title(f'Historical and Forecasted Sales for {product_id} at {store_id}')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Sales Quantity')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../images/historical_and_forecasted_sales.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Calculate Optimal Inventory Levels\n",
    "\n",
    "Now, let's calculate the optimal inventory levels based on the forecasted demand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Function to calculate optimal inventory levels\n",
    "def calculate_optimal_inventory(forecasted_demand, safety_stock_factor=1.5, lead_time_days=3):\n",
    "    # Convert lead time from days to weeks (assuming 7 days per week)\n",
    "    lead_time_weeks = lead_time_days / 7\n",
    "    \n",
    "    # Calculate optimal inventory levels\n",
    "    optimal_inventory = []\n",
    "    for demand in forecasted_demand:\n",
    "        # Base inventory = forecasted demand + safety stock\n",
    "        base_inventory = demand * (1 + safety_stock_factor * lead_time_weeks)\n",
    "        optimal_inventory.append(round(base_inventory))\n",
    "    \n",
    "    return optimal_inventory\n",
    "\n",
    "# Calculate optimal inventory levels\n",
    "optimal_inventory = calculate_optimal_inventory(future_predictions)\n",
    "\n",
    "# Add to the forecast dataframe\n",
    "forecast_df['Optimal_Inventory'] = optimal_inventory\n",
    "print(\"Forecasted Sales and Optimal Inventory Levels:\")\n",
    "print(forecast_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot forecasted sales and optimal inventory levels\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Bar chart for forecasted sales\n",
    "plt.bar(forecast_df['Week_Start'], forecast_df['Forecasted_Sales'], color='skyblue', label='Forecasted Sales')\n",
    "\n",
    "# Line chart for optimal inventory\n",
    "plt.plot(forecast_df['Week_Start'], forecast_df['Optimal_Inventory'], color='red', marker='o', label='Optimal Inventory')\n",
    "\n",
    "plt.title(f'Forecasted Sales and Optimal Inventory for {product_id} at {store_id}')\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Quantity')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../images/forecasted_sales_and_optimal_inventory.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Results\n",
    "\n",
    "Let's save our forecasting results and model for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a directory for models if it doesn't exist\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "# Save the model\n",
    "model.save('../models/lstm_model.h5')\n",
    "print(\"Model saved to '../models/lstm_model.h5'\")\n",
    "\n",
    "# Save the forecast results\n",
    "forecast_df.to_csv('../data/forecast_results.csv', index=False)\n",
    "print(\"Forecast results saved to '../data/forecast_results.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary\n",
    "\n",
    "In this notebook, we have:\n",
    "1. Loaded and prepared the preprocessed data for LSTM modeling\n",
    "2. Built and trained an LSTM model for time series forecasting\n",
    "3. Evaluated the model's performance on test data\n",
    "4. Forecasted future demand for the next 4 weeks\n",
    "5. Calculated optimal inventory levels based on the forecasted demand\n",
    "6. Visualized the results and saved them for future use\n",
    "\n",
    "The model can now be used to forecast demand and optimize inventory levels for any product-store combination."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
